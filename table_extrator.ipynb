{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from pdfminer import pdfpage\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import camelot\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_df_image(table,\n",
    "                  max_cols=-1,\n",
    "                  max_rows=-1):\n",
    "    \"\"\"Return dataframe as image.\"\"\"\n",
    "    with tempfile.NamedTemporaryFile(suffix='.jpg',\n",
    "                                     delete=False) as tmp:\n",
    "        dfi.export(table, tmp.name, max_cols=max_cols, max_rows=max_rows)\n",
    "        image = mpimg.imread(tmp.name)\n",
    "        return image\n",
    "\n",
    "\n",
    "def make_lines_image(lines,\n",
    "                     mrgn=15,\n",
    "                     background=(255, 255, 255),\n",
    "                     text_color=(0, 0, 0),\n",
    "                     font_size=10):\n",
    "    \"\"\"Return raw text in lines as image.\"\"\"\n",
    "    lines = pd.Series(lines)\n",
    "    longest_line = lines[lines.str.len().idxmax()]\n",
    "    image = Image.new(\"RGBA\", (1, 1))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    monospace = ImageFont.truetype(r'ะก:\\Windows\\Fonts\\cour.ttf', font_size)\n",
    "    line_width, line_height = draw.textsize(longest_line, monospace)\n",
    "    img_width, img_height = (line_width + mrgn * 2,\n",
    "                             len(lines) * line_height + mrgn * 2)\n",
    "    image = Image.new(\"RGBA\", (img_width, img_height), background)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    x, y0 = (mrgn, mrgn)\n",
    "    for n, line in enumerate(lines):\n",
    "        y = y0 + n * line_height\n",
    "        draw.text((x, y), line, text_color, monospace)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(extract_no):\n",
    "    pdfminer_string = StringIO()\n",
    "    pageno = 0\n",
    "    with open(PDF, \"rb\") as in_file:\n",
    "        parser = PDFParser(in_file)\n",
    "        doc = PDFDocument(parser)\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        device = TextConverter(rsrcmgr,\n",
    "                            pdfminer_string,\n",
    "                            laparams=LAParams())\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.create_pages(doc):\n",
    "            if pageno == extract_no:\n",
    "                interpreter.process_page(page)\n",
    "            pageno = pageno+1\n",
    "        # pdfminer_lines = pdfminer_string.getvalue().splitlines()\n",
    "    pdfminer_lines = [ln for ln in pdfminer_lines if ln]\n",
    "    return pdfminer_lines\n",
    "\n",
    "def camel(extract_no):\n",
    "    # layout_kwargs={'char_margin':0.1, 'line_margin':2, 'boxes_flow':1}\n",
    "    # NON OCR CALL\n",
    "    #tables, text = camelot.read_pdf(PDF,flavor='lattice', strip_text='\\n', pages=str(extract_no), backend=\"poppler\", split_text=True, process_background=False, copy_text=['h','v'], line_scale=60)\n",
    "    tables, text = camelot.read_pdf(PDF,flavor='lattice_ocr', pages=str(extract_no))\n",
    "    camelot.plot(tables[0], kind='contour')\n",
    "    for i in range(0,len(tables)):\n",
    "        camelot.plot(tables[i], kind='grid')\n",
    "    tables.export(r'C:\\Data\\Output\\tables\\table.csv', f='csv', compress=False) # json, excel, html, markdown, sqlite\n",
    "    print(tables.export(r'C:\\Data\\Output\\tables\\table.txt',f='txt'))\n",
    "    tablesfin, line, dic, header = [], '', {}, 0\n",
    "    '''                                              Testing new logic below / / / /\n",
    "    for table in text:\n",
    "        para = []\n",
    "        for row_index,row in enumerate(table):\n",
    "            for col_index,col in enumerate(row):\n",
    "                if len(table[0][col_index]) > 2:\n",
    "                    print(f'/-------{table[0][col_index]}|-------|')\n",
    "                    if row_index > 0:\n",
    "                        line = f'{table[0][col_index]} - {col}, '\n",
    "                else:\n",
    "                    if row_index > 1:\n",
    "                        line = f'{table[1][col_index]} - {col}, '\n",
    "                print(f'\\n{line}')\n",
    "                para.append(line)\n",
    "        tabel = ' '.join(para)\n",
    "        tablesfin.append(tabel)\n",
    "    for table in tablesfin:\n",
    "        print(f'\\n\\n /////------ After sentencing logic ------///// \\n{table}\\n')\n",
    "    '''\n",
    "    for table in text:\n",
    "        para = []\n",
    "        for row_index,row in enumerate(table):\n",
    "            for col_index,col in enumerate(row):\n",
    "                dic.setdefault(f'Col{col_index}', [])\n",
    "                if row_index <= header:\n",
    "                    if table[row_index][col_index] not in dic.get(f'Col{col_index}', ''):\n",
    "                        dic[f'Col{col_index}'].append(table[row_index][col_index])\n",
    "                if table[row_index][col_index] in dic.get(f'Col{col_index}', ''):\n",
    "                    header = row_index\n",
    "                else:\n",
    "                    head = ' '.join(dic.get(f'Col{col_index}', ''))\n",
    "                    line = f'{head} - {table[row_index][col_index]},'\n",
    "                #print(f'\\n{line}')\n",
    "                para.append(line)\n",
    "            para.append('\\n')\n",
    "        tabel = ' '.join(para)\n",
    "        tablesfin.append(tabel)\n",
    "    #for table in tablesfin:\n",
    "        #print(f'\\n\\n\\n /////------ After sentencing logic ------///// \\n{table}\\n')\n",
    "        \n",
    "'''\n",
    "REPLACE IN core.py in camelot package:\n",
    "\n",
    "    def to_txt(self, **kwargs):\n",
    "        \"\"\"Prints as raw text.\n",
    "\n",
    "        For kwargs, check :meth:`pandas.DataFrame.to_string`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Output filepath.\n",
    "\n",
    "        \"\"\"\n",
    "        rawtxt = {\"encoding\": \"utf-8\", \"index\": False, \"header\": False, \"quoting\": csv.QUOTE_NONE, \"doublequote\": False, \"escapechar\":'?', \"sep\":' '}\n",
    "        text = self.df.to_csv(**rawtxt).replace('?', '')\n",
    "        #print(text)\n",
    "        return(text)\n",
    "        \n",
    "        def export(self, path, f=\"csv\", compress=False):\n",
    "        \"\"\"Exports the list of tables to specified file format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Output filepath.\n",
    "        f : str\n",
    "            File format. Can be csv, excel, html, json, markdown or sqlite.\n",
    "        compress : bool\n",
    "            Whether or not to add files to a ZIP archive.\n",
    "\n",
    "        \"\"\"\n",
    "        dirname = os.path.dirname(path)\n",
    "        basename = os.path.basename(path)\n",
    "        root, ext = os.path.splitext(basename)\n",
    "        if compress:\n",
    "            dirname = tempfile.mkdtemp()\n",
    "\n",
    "        kwargs = {\"path\": path, \"dirname\": dirname, \"root\": root, \"ext\": ext}\n",
    "\n",
    "        if f in [\"csv\", \"html\", \"json\", \"markdown\"]:\n",
    "            self._write_file(f=f, **kwargs)\n",
    "            if compress:\n",
    "                self._compress_dir(**kwargs)\n",
    "        elif f == \"excel\":\n",
    "            filepath = os.path.join(dirname, basename)\n",
    "            writer = pd.ExcelWriter(filepath)\n",
    "            for table in self._tables:\n",
    "                sheet_name = f\"page-{table.page}-table-{table.order}\"\n",
    "                table.df.to_excel(writer, sheet_name=sheet_name, encoding=\"utf-8\")\n",
    "            writer.save()\n",
    "            if compress:\n",
    "                zipname = os.path.join(os.path.dirname(path), root) + \".zip\"\n",
    "                with zipfile.ZipFile(zipname, \"w\", allowZip64=True) as z:\n",
    "                    z.write(filepath, os.path.basename(filepath))\n",
    "        elif f == \"sqlite\":\n",
    "            filepath = os.path.join(dirname, basename)\n",
    "            for table in self._tables:\n",
    "                table.to_sqlite(filepath)\n",
    "            if compress:\n",
    "                zipname = os.path.join(os.path.dirname(path), root) + \".zip\"\n",
    "                with zipfile.ZipFile(zipname, \"w\", allowZip64=True) as z:\n",
    "                    z.write(filepath, os.path.basename(filepath))\n",
    "        elif f == \"txt\":\n",
    "            for table in self._tables:\n",
    "                text = table.to_txt()\n",
    "                return text\n",
    "'''                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracted(pdfminer_lines):\n",
    "    # pd.Series(pdfminer_lines)\n",
    "    fig, ax = plt.subplots(figsize=(50,25))\n",
    "    title = 'pdfminer.six 20201018'\n",
    "    for i,img in enumerate(map(make_lines_image,\n",
    "                                [pdfminer_lines])):\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_adjustable(\"box\")\n",
    "        ax.title.set_text(title)\n",
    "        ax.imshow(img)\n",
    "    return fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='gtp04'\n",
    "PDF = f'file:///C:/Data/test/{filename}.pdf'\n",
    "pagen = 45\n",
    "#lines = extract(pagen)\n",
    "camel(pagen)\n",
    "#extracted(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8514d1ffa18807466e1e1005c0ca77f2f21c1b6d7794e0ad757c55b4086bfbc8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('classification': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
